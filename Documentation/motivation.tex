% Conduct a motivating experiment that explains
%     Why is this problem important
%     Assuming caches are always good
%         Why multi tier
%         Why partitioning
%             Consider ~10-100 VMs on a single host
%             Global cache is not efficient

\section{Motivation}
The motivation for this work are two-fold. First, we show why we need a smart partitioning algorithm. Second, we show why we need a two-layer cache.

\subsection{The case for smart partitioning}

\begin{figure}[tb]
\setlength{\belowcaptionskip}{-15pt}
\centering
\includegraphics[width=3in]{figures/hitrate_fake}
\caption{VMs competing for resources}
\label{fig:compete}
\end{figure}

The need for partitioning the SSD cache has been studied in [vCacheShare, ...]. To illustrate we conduct a simple experiment where two VMs, namely VM1 and VM2, residing in the same host share a caching device. From figure XX, one can see that VM1 has a high random I/O with a very low hit ratio while VM2 has a low I/O but has a high hit rate. Figure~\ref{fig:compete} , shows that despite VM2 could benefit largely from a cache, it has a very low space allocation in the cache, due to contention from VM1. From figure XX and YY, one can infer that contention can make a cache entirely unusable.

\subsection{The case for two-layer cache}

Each VM in a data center come with their own priority and Service Level Agreement. The priority if not explicitly mentioned, it can be inferred from the type of service they request at the time of their creation. VMs that run web services expect to have a very minimal latency as the response time is the most important criterion. On the other hand, VMs that run database servers, don't care about latency as much, but they want to optimize for throughput. It is the same with batch jobs, where the life time of the jobs is very short- jobs come in for a quick computation, and once they are done, there is a single reply with the result and they are done.

Optimizing for each of the different kinds of VMs on a single physical machine is a very diffucult task. Instead, we take the latency as a common denominator and use it as a tuning parameter to meet the SLAs of the VMs. For instance, interactive VMs that has a very low I/O, but a very high hit rate can be ``separated" and placed in the lowest latency cache for high reponsiveness. 
